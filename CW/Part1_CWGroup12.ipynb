{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******F20DL Coursework Part 1******"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialization of Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB \n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import CategoricalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing all coursework Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_class_x_train=pd.read_csv('./Traffic_Sign/Binary_Classification/x_train_bin.csv')\n",
    "binary_class_y_train=pd.read_csv('./Traffic_Sign/Binary_Classification/y_train_bin.csv')\n",
    "binary_class_x_test=pd.read_csv('./Traffic_Sign/Binary_Classification/x_test_bin.csv')\n",
    "binary_class_y_test=pd.read_csv('./Traffic_Sign/Binary_Classification/y_test_bin.csv')\n",
    "\n",
    "complete_x_train=pd.read_csv('./Traffic_Sign/CompleteDataSet/x_train_all.csv')\n",
    "complete_y_train=pd.read_csv('./Traffic_Sign/CompleteDataSet/y_train_all.csv')\n",
    "complete_x_test=pd.read_csv('./Traffic_Sign/CompleteDataSet/x_test_all.csv')\n",
    "complete_y_test=pd.read_csv('./Traffic_Sign/CompleteDataSet/y_test_all.csv')\n",
    "\n",
    "onevsall_y_train_0=pd.read_csv('./Traffic_Sign/OnevrsAll/0_vrs_all/y_train_0.csv')\n",
    "onevsall_y_train_1=pd.read_csv('./Traffic_Sign/OnevrsAll/1_vrs_all/y_train_1.csv')\n",
    "onevsall_y_train_2=pd.read_csv('./Traffic_Sign/OnevrsAll/2_vrs_all/y_train_2.csv')\n",
    "onevsall_y_train_3=pd.read_csv('./Traffic_Sign/OnevrsAll/3_vrs_all/y_train_3.csv')\n",
    "onevsall_y_train_4=pd.read_csv('./Traffic_Sign/OnevrsAll/4_vrs_all/y_train_4.csv')\n",
    "onevsall_y_train_5=pd.read_csv('./Traffic_Sign/OnevrsAll/5_vrs_all/y_train_5.csv')\n",
    "onevsall_y_train_6=pd.read_csv('./Traffic_Sign/OnevrsAll/6_vrs_all/y_train_6.csv')\n",
    "onevsall_y_train_7=pd.read_csv('./Traffic_Sign/OnevrsAll/7_vrs_all/y_train_7.csv')\n",
    "onevsall_y_train_8=pd.read_csv('./Traffic_Sign/OnevrsAll/8_vrs_all/y_train_8.csv')\n",
    "onevsall_y_train_9=pd.read_csv('./Traffic_Sign/OnevrsAll/9_vrs_all/y_train_9.csv')\n",
    "\n",
    "# Specs assumes 0 is true and 1 is false. So we have to reverse that\n",
    "\n",
    "def inverse_num(i):\n",
    "    if i == 1: return 0\n",
    "    else: return 1\n",
    "\n",
    "onevsall_y_train_0 = [[inverse_num(i)] for i in onevsall_y_train_0.copy().to_numpy()]\n",
    "onevsall_y_train_1 = [[inverse_num(i)] for i in onevsall_y_train_1.copy().to_numpy()]\n",
    "onevsall_y_train_2 = [[inverse_num(i)] for i in onevsall_y_train_2.copy().to_numpy()]\n",
    "onevsall_y_train_3 = [[inverse_num(i)] for i in onevsall_y_train_3.copy().to_numpy()]\n",
    "onevsall_y_train_4 = [[inverse_num(i)] for i in onevsall_y_train_4.copy().to_numpy()]\n",
    "onevsall_y_train_5 = [[inverse_num(i)] for i in onevsall_y_train_5.copy().to_numpy()]\n",
    "onevsall_y_train_6 = [[inverse_num(i)] for i in onevsall_y_train_6.copy().to_numpy()]\n",
    "onevsall_y_train_7 = [[inverse_num(i)] for i in onevsall_y_train_7.copy().to_numpy()]\n",
    "onevsall_y_train_8 = [[inverse_num(i)] for i in onevsall_y_train_8.copy().to_numpy()]\n",
    "onevsall_y_train_9 = [[inverse_num(i)] for i in onevsall_y_train_9.copy().to_numpy()]\n",
    "\n",
    "complete_x_train = complete_x_train.astype('float') / 255\n",
    "complete_x_test = complete_x_test.astype('float') / 255\n",
    "\n",
    "final_dataset = complete_x_train.copy()\n",
    "final_dataset['class']=complete_y_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1. Visualization and Initial Data Exploration**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Description of x and y datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_x_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation of a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_x_train.iloc[0].to_numpy().reshape(48,48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image(num):\n",
    "    plt.imshow(complete_x_train.iloc[num].to_numpy().reshape(48,48),cmap=\"grey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_image(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation of an image from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_toshow = [0,210,2435,6085,7030,8275,8635,8875,9415,9685]\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "for i in range (0, len(img_toshow)):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(complete_x_train.iloc[img_toshow[i]].to_numpy().reshape(48,48), cmap='gray')\n",
    "    plt.xlabel(\"Class \"+str(complete_y_train.iloc[img_toshow[i]].to_numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "for i in range (0, len(img_toshow)):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(complete_x_train.iloc[img_toshow[i]].to_numpy().reshape(48,48))\n",
    "    plt.colorbar()\n",
    "    plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refining and balancing out the dataset to perform better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dataset = final_dataset.groupby('class', group_keys=False).apply(lambda x: x.sample(frac=0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(temp_dataset['class'].value_counts()) / len(temp_dataset) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = temp_dataset['class'].value_counts().min()\n",
    "balanced_dataset = temp_dataset.groupby('class', group_keys=False).apply(lambda x: x.sample(min_val))\n",
    "(balanced_dataset['class'].value_counts()) / len(balanced_dataset) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dataset_x = balanced_dataset.iloc[:,:2304]\n",
    "balanced_dataset_y = balanced_dataset.iloc[:,2304:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking correlation with unbalanced and balanced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_corr = final_dataset.corr()\n",
    "# final_corr['class'].sort_values(ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced_corr = balanced_dataset.corr()\n",
    "# balanced_corr['class'].sort_values(ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naïve Bayes Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_naivebayes_print(classifier, dataset_train_x, dataset_train_y, dataset_test_x, dataset_test_y):\n",
    "    clf = None\n",
    "    if classifier == \"gaussian\":\n",
    "        clf = GaussianNB()\n",
    "    elif classifier == \"multinomial\":\n",
    "        clf = MultinomialNB()\n",
    "    elif classifier == \"complement\":\n",
    "        clf = ComplementNB()\n",
    "    elif classifier == \"categorical\":\n",
    "        clf = CategoricalNB(min_categories=10)\n",
    "    else:\n",
    "        clf = None\n",
    "    clf.fit(dataset_train_x,dataset_train_y)\n",
    "    complete_y_pred = clf.predict(dataset_test_x)\n",
    "    print(\"Accuracy:\", accuracy_score(dataset_test_y, complete_y_pred))\n",
    "    print(\"Precision: \" , precision_score(dataset_test_y, complete_y_pred, average='weighted'))\n",
    "    print('Recall score: ', recall_score(dataset_test_y, complete_y_pred, average='weighted'))\n",
    "    print('F-measure: ', f1_score(dataset_test_y, complete_y_pred, average='weighted'))\n",
    "    print(classification_report(dataset_test_y, complete_y_pred))\n",
    "    conf_matrix = confusion_matrix(dataset_test_y, complete_y_pred)\n",
    "    class_names = list(set(dataset_test_y) | set(complete_y_pred))\n",
    "    cm_display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
    "    cm_display.plot()\n",
    "    plt.show()\n",
    "    tpr = conf_matrix[1,1]/(conf_matrix[1,1]+conf_matrix[1,0])\n",
    "    fpr = conf_matrix[0,0]/(conf_matrix[0,0]+conf_matrix[0,1])\n",
    "    print(\"True Positive Rate: \", tpr)\n",
    "    print(\"False Positive Rate: \", fpr)\n",
    "\n",
    "def run_naivebayes(classifier, dataset_train_x, dataset_train_y, dataset_test_x, dataset_test_y):\n",
    "    clf = None\n",
    "    ret_arr=[]\n",
    "    if classifier == \"gaussian\":\n",
    "        clf = GaussianNB()\n",
    "    elif classifier == \"multinomial\":\n",
    "        clf = MultinomialNB()\n",
    "    elif classifier == \"complement\":\n",
    "        clf = ComplementNB()\n",
    "    elif classifier == \"categorical\":\n",
    "        clf = CategoricalNB(min_categories=10)\n",
    "    else:\n",
    "        clf = None\n",
    "    clf.fit(dataset_train_x,dataset_train_y)\n",
    "    complete_y_pred = clf.predict(dataset_test_x)\n",
    "    ret_arr = [accuracy_score(dataset_test_y, complete_y_pred), \n",
    "            precision_score(dataset_test_y, complete_y_pred, average='weighted'), \n",
    "            recall_score(dataset_test_y, complete_y_pred, average='weighted'),\n",
    "            f1_score(dataset_test_y, complete_y_pred, average='weighted'),\n",
    "            classification_report(dataset_test_y, complete_y_pred),\n",
    "            confusion_matrix(dataset_test_y, complete_y_pred)\n",
    "            ]\n",
    "    return ret_arr\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Naive Bayes Classifier using complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_naivebayes_print(\"gaussian\",complete_x_train,complete_y_train,complete_x_test,complete_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes Classifier using complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_naivebayes_print(\"multinomial\",complete_x_train,complete_y_train,complete_x_test,complete_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complement Naive Bayes Classifier using complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_naivebayes_print(\"complement\",complete_x_train,complete_y_train,complete_x_test,complete_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical Naive Bayes Classifier using complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_naivebayes_print(\"categorical\",complete_x_train,complete_y_train,complete_x_test,complete_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Naive Bayes Classifier using stratified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_naivebayes_print(\"gaussian\",balanced_dataset_x,balanced_dataset_y,complete_x_test,complete_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes Classifier using stratified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_naivebayes_print(\"multinomial\",balanced_dataset_x,balanced_dataset_y,complete_x_test,complete_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complement Naive Bayes Classifier using stratified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_naivebayes_print(\"complement\",balanced_dataset_x,balanced_dataset_y,complete_x_test,complete_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical Naive Bayes Classifier using stratified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_naivebayes_print(\"categorical\",balanced_dataset_x,balanced_dataset_y,complete_x_test,complete_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Dataset using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA \n",
    "pca = PCA(n_components = len(balanced_dataset_x))\n",
    "X2D = pca.fit_transform(balanced_dataset_x)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum >= 0.95) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = d)\n",
    "X_reduced = pd.DataFrame(pca.fit_transform(balanced_dataset_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dataset_x = pd.DataFrame(pca.inverse_transform(X_reduced))\n",
    "pca_dataset_x[pca_dataset_x < 0] = 0\n",
    "pca_dataset_y = balanced_dataset_y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussianclf = GaussianNB()\n",
    "multinomialclf = MultinomialNB()\n",
    "complementclf = ComplementNB()\n",
    "categoricalclf = CategoricalNB(min_categories=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Naive Bayes Classifier using PCA recovered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_naivebayes_print(\"gaussian\",pca_dataset_x,pca_dataset_y,complete_x_test,complete_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes Classifier using PCA recovered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_naivebayes_print(\"multinomial\",pca_dataset_x,pca_dataset_y,complete_x_test,complete_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complement Naive Bayes Classifier using PCA recovered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_naivebayes_print(\"complement\",pca_dataset_x,pca_dataset_y,complete_x_test,complete_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical Naive Bayes Classifier using PCA recovered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_naivebayes_print(\"categorical\",pca_dataset_x,pca_dataset_y,complete_x_test,complete_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selecting best correlating features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods to select the top correlating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_arr_data = [\n",
    "                onevsall_y_train_0.copy(),\n",
    "                onevsall_y_train_1.copy(),\n",
    "                onevsall_y_train_2.copy(),\n",
    "                onevsall_y_train_3.copy(),\n",
    "                onevsall_y_train_4.copy(),\n",
    "                onevsall_y_train_5.copy(),\n",
    "                onevsall_y_train_6.copy(),\n",
    "                onevsall_y_train_7.copy(),\n",
    "                onevsall_y_train_8.copy(),\n",
    "                onevsall_y_train_9.copy()\n",
    "            ]\n",
    "\n",
    "x_data = complete_x_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopFeatureMethod1(x):\n",
    "    return_arr = []\n",
    "    for i in class_arr_data:\n",
    "        bestfeatures = SelectKBest(score_func=chi2, k=x//len(class_arr_data))\n",
    "        fit = bestfeatures.fit(x_data,i)\n",
    "        dfscores = pd.DataFrame(fit.scores_)\n",
    "        dfcolumns = pd.DataFrame(x_data.columns)\n",
    "        featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "        featureScores.columns = ['Specs','Score']\n",
    "        return_arr = np.unique(np.concatenate((return_arr,featureScores.nlargest(x//len(class_arr_data),'Score')['Specs']),0))\n",
    "    return return_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopFeatureMethod2(x):\n",
    "    features_array = [[]]*10\n",
    "    return_arr = [[]]*3\n",
    "    for i in range (0,len(class_arr_data)):\n",
    "        bestfeatures = SelectKBest(score_func=chi2, k=x//len(class_arr_data))\n",
    "        fit = bestfeatures.fit(x_data,class_arr_data[i])\n",
    "        dfscores = pd.DataFrame(fit.scores_)\n",
    "        dfcolumns = pd.DataFrame(x_data.columns)\n",
    "        featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "        featureScores.columns = ['Specs','Score']\n",
    "        features_array[i]=featureScores.nlargest(x//len(class_arr_data),'Score')['Specs']\n",
    "    for i in range (0,10):\n",
    "        return_arr[0] = np.unique(np.concatenate((return_arr[0], features_array[i][0:x//len(class_arr_data)]),0))\n",
    "        return_arr[1] = np.unique(np.concatenate((return_arr[1], features_array[i][0:x//(len(class_arr_data)*2)]),0))\n",
    "        return_arr[2] = np.unique(np.concatenate((return_arr[2], features_array[i][0:x//(len(class_arr_data)*4)]),0))\n",
    "    return return_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "temp1 = getTopFeatureMethod1(200)\n",
    "temp2 = getTopFeatureMethod1(100)\n",
    "temp3 = getTopFeatureMethod1(75)\n",
    "print(\"Time taken to compute best features using method 1 : \",time.time()-start_time)\n",
    "\n",
    "start_time = time.time()\n",
    "temp = getTopFeatureMethod2(200)\n",
    "print(\"Time taken to compute best features using method 2 : \",time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1_method_1 = balanced_dataset_x.copy()[temp1]\n",
    "dataset2_method_1 = balanced_dataset_x.copy()[temp2]\n",
    "dataset3_method_1 = balanced_dataset_x.copy()[temp3]\n",
    "\n",
    "dataset1_method_2 = balanced_dataset_x.copy()[temp[0]]\n",
    "dataset2_method_2 = balanced_dataset_x.copy()[temp[1]]\n",
    "dataset3_method_2 = balanced_dataset_x.copy()[temp[2]]\n",
    "\n",
    "dataset1_test_method_1 = complete_x_test.copy()[temp1]\n",
    "dataset2_test_method_1 = complete_x_test.copy()[temp2]\n",
    "dataset3_test_method_1 = complete_x_test.copy()[temp3]\n",
    "\n",
    "dataset1_test_method_2 = complete_x_test.copy()[temp[0]]\n",
    "dataset2_test_method_2 = complete_x_test.copy()[temp[1]]\n",
    "dataset3_test_method_2 = complete_x_test.copy()[temp[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running Naïve Bayes Classifier on the datasets produced by running the methods mentioned in above section**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    [(dataset1_method_1, dataset1_test_method_1), (dataset2_method_1, dataset2_test_method_1), (dataset3_method_1, dataset3_test_method_1)],\n",
    "    [(dataset1_method_2, dataset1_test_method_2), (dataset2_method_2, dataset2_test_method_2), (dataset3_method_2, dataset3_test_method_2)]\n",
    "]\n",
    "\n",
    "bayes = [\"gaussian\", \"multinomial\", \"complement\", \"categorical\"]\n",
    "\n",
    "report = [[[[]]*len(bayes)]*len(datasets[0])]*len(datasets)\n",
    "\n",
    "for i in range (0,len(datasets)):\n",
    "    for j in range (0,len(datasets[i])):\n",
    "        for k in range (0,len(bayes)):\n",
    "            report[i][j][k] = run_naivebayes(bayes[k], datasets[i][j][0], balanced_dataset_y, datasets[i][j][1], complete_y_test)\n",
    "            report[i][j][k].append(bayes[k].capitalize())\n",
    "\n",
    "def gen_report(report):\n",
    "    for i in range (0,len(report)):\n",
    "        print(\"*\"*100)\n",
    "        print(\"Using Method \",i+1)\n",
    "        print(\"*\"*100)\n",
    "        acc=[]\n",
    "        prec=[]\n",
    "        recall=[]\n",
    "        f1=[]\n",
    "        dataset=[]\n",
    "        baye=[]\n",
    "        for j in range (0,len(report[i])):\n",
    "            for k in range (0,len(report[i][j])):\n",
    "                if(report[i][j]==[]):\n",
    "                    continue\n",
    "                acc.append(report[i][j][k][0])\n",
    "                prec.append(report[i][j][k][1])\n",
    "                recall.append(report[i][j][k][2])\n",
    "                f1.append(report[i][j][k][3])\n",
    "                dataset.append(j+1)\n",
    "                baye.append(report[i][j][k][6])\n",
    "        temp_table = {\"Dataset\":dataset,\"Naive Bayes\":baye,\"Accuracy\":acc,\"Precision\":prec,\"Recall Score\":recall,\"F1 Score\":f1}\n",
    "        print(pd.DataFrame(temp_table))\n",
    "        print()\n",
    "\n",
    "gen_report(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "x_train_sm = np.apply_along_axis(\n",
    "    func1d=lambda img: cv2.resize(img.reshape(48, 48), dsize=(16, 16)),\n",
    "    axis=1, arr=complete_x_train).reshape(-1, 16*16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
