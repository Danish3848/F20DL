{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3,5)\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pandas.plotting import scatter_matrix\n",
    "import time\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, roc_curve\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB \n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_class_x_train=pd.read_csv('./Traffic_Sign/Binary_Classification/x_train_bin.csv')\n",
    "binary_class_y_train=pd.read_csv('./Traffic_Sign/Binary_Classification/y_train_bin.csv')\n",
    "binary_class_x_test=pd.read_csv('./Traffic_Sign/Binary_Classification/x_test_bin.csv')\n",
    "binary_class_y_test=pd.read_csv('./Traffic_Sign/Binary_Classification/y_test_bin.csv')\n",
    "\n",
    "complete_x_train=pd.read_csv('./Traffic_Sign/CompleteDataSet/x_train_all.csv')\n",
    "complete_y_train=pd.read_csv('./Traffic_Sign/CompleteDataSet/y_train_all.csv')\n",
    "complete_x_test=pd.read_csv('./Traffic_Sign/CompleteDataSet/x_test_all.csv')\n",
    "complete_y_test=pd.read_csv('./Traffic_Sign/CompleteDataSet/y_test_all.csv')\n",
    "\n",
    "onevsall_y_train_0=pd.read_csv('./Traffic_Sign/OnevrsAll/0_vrs_all/y_train_0.csv')\n",
    "onevsall_y_train_1=pd.read_csv('./Traffic_Sign/OnevrsAll/1_vrs_all/y_train_1.csv')\n",
    "onevsall_y_train_2=pd.read_csv('./Traffic_Sign/OnevrsAll/2_vrs_all/y_train_2.csv')\n",
    "onevsall_y_train_3=pd.read_csv('./Traffic_Sign/OnevrsAll/3_vrs_all/y_train_3.csv')\n",
    "onevsall_y_train_4=pd.read_csv('./Traffic_Sign/OnevrsAll/4_vrs_all/y_train_4.csv')\n",
    "onevsall_y_train_5=pd.read_csv('./Traffic_Sign/OnevrsAll/5_vrs_all/y_train_5.csv')\n",
    "onevsall_y_train_6=pd.read_csv('./Traffic_Sign/OnevrsAll/6_vrs_all/y_train_6.csv')\n",
    "onevsall_y_train_7=pd.read_csv('./Traffic_Sign/OnevrsAll/7_vrs_all/y_train_7.csv')\n",
    "onevsall_y_train_8=pd.read_csv('./Traffic_Sign/OnevrsAll/8_vrs_all/y_train_8.csv')\n",
    "onevsall_y_train_9=pd.read_csv('./Traffic_Sign/OnevrsAll/9_vrs_all/y_train_9.csv')\n",
    "\n",
    "# Specs assumes 0 is true and 1 is false. So we have to reverse that\n",
    "\n",
    "def inverse_num(i):\n",
    "    if i == 1: return 0\n",
    "    else: return 1\n",
    "\n",
    "onevsall_y_train_0 = [[inverse_num(i)] for i in onevsall_y_train_0.copy().to_numpy()]\n",
    "onevsall_y_train_1 = [[inverse_num(i)] for i in onevsall_y_train_1.copy().to_numpy()]\n",
    "onevsall_y_train_2 = [[inverse_num(i)] for i in onevsall_y_train_2.copy().to_numpy()]\n",
    "onevsall_y_train_3 = [[inverse_num(i)] for i in onevsall_y_train_3.copy().to_numpy()]\n",
    "onevsall_y_train_4 = [[inverse_num(i)] for i in onevsall_y_train_4.copy().to_numpy()]\n",
    "onevsall_y_train_5 = [[inverse_num(i)] for i in onevsall_y_train_5.copy().to_numpy()]\n",
    "onevsall_y_train_6 = [[inverse_num(i)] for i in onevsall_y_train_6.copy().to_numpy()]\n",
    "onevsall_y_train_7 = [[inverse_num(i)] for i in onevsall_y_train_7.copy().to_numpy()]\n",
    "onevsall_y_train_8 = [[inverse_num(i)] for i in onevsall_y_train_8.copy().to_numpy()]\n",
    "onevsall_y_train_9 = [[inverse_num(i)] for i in onevsall_y_train_9.copy().to_numpy()]\n",
    "\n",
    "complete_x_train = complete_x_train.astype('float') / 255\n",
    "complete_x_test = complete_x_test.astype('float') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_denoiser(arr):\n",
    "    pixel_array = arr\n",
    "    reshaped_array = pixel_array.reshape((48, 48))\n",
    "    normalized_array = np.uint8(reshaped_array * 255)\n",
    "    if normalized_array.ndim != 2:\n",
    "        raise ValueError(\"The image should have 2 dimensions\")\n",
    "    thresholded_image = cv2.adaptiveThreshold(normalized_array, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    return thresholded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_x_train = np.apply_along_axis(\n",
    "    func1d=lambda img: img_denoiser(img),\n",
    "    axis=1, arr=complete_x_train).reshape(-1, 48*48)\n",
    "\n",
    "complete_x_test = np.apply_along_axis(\n",
    "    func1d=lambda img: img_denoiser(img),\n",
    "    axis=1, arr=complete_x_test).reshape(-1, 48*48)\n",
    "\n",
    "complete_x_train = complete_x_train.astype('float') / 255\n",
    "complete_x_test = complete_x_test.astype('float') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_x_train = pd.DataFrame(complete_x_train)\n",
    "complete_x_test = pd.DataFrame(complete_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = complete_x_train.copy()\n",
    "final_dataset['class']=complete_y_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_train_classifier(classifier, dataset_train_x, dataset_train_y):\n",
    "    clf = None\n",
    "    if classifier == \"gaussian\":\n",
    "        clf = GaussianNB()\n",
    "    elif classifier == \"multinomial\":\n",
    "        clf = MultinomialNB()\n",
    "    elif classifier == \"complement\":\n",
    "        clf = ComplementNB()\n",
    "    elif classifier == \"categorical\":\n",
    "        clf = CategoricalNB(min_categories=10)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown classifier: {classifier}\")\n",
    "    clf.fit(dataset_train_x, dataset_train_y)\n",
    "    return clf\n",
    "\n",
    "def run_naivebayes(classifier, dataset_train_x, dataset_train_y, dataset_test_x, dataset_test_y):\n",
    "    clf = init_train_classifier(classifier, dataset_train_x, dataset_train_y)\n",
    "    complete_y_pred = clf.predict(dataset_test_x)\n",
    "    ret_arr = [\n",
    "        accuracy_score(dataset_test_y, complete_y_pred), \n",
    "        precision_score(dataset_test_y, complete_y_pred, average='weighted'), \n",
    "        recall_score(dataset_test_y, complete_y_pred, average='weighted'),\n",
    "        f1_score(dataset_test_y, complete_y_pred, average='weighted'),\n",
    "        classification_report(dataset_test_y, complete_y_pred),\n",
    "        confusion_matrix(dataset_test_y, complete_y_pred)\n",
    "    ]\n",
    "    return ret_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dataset = final_dataset.groupby('class', group_keys=False)\n",
    "avg_val = int(temp_dataset['class'].value_counts().mean())\n",
    "\n",
    "balanced_dataset = pd.DataFrame()\n",
    "\n",
    "for i in range(0,10):\n",
    "    if (len(final_dataset[final_dataset['class']==i])<=avg_val):\n",
    "        balanced_dataset = pd.concat([balanced_dataset, final_dataset[final_dataset['class']==i].sample(avg_val, replace=True)])\n",
    "    else:\n",
    "        balanced_dataset = pd.concat([balanced_dataset, final_dataset[final_dataset['class']==i].sample(avg_val)])\n",
    "\n",
    "balanced_dataset_x = balanced_dataset.iloc[:,:2304]\n",
    "balanced_dataset_y = balanced_dataset.iloc[:,2304:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_arr_data = [\n",
    "                onevsall_y_train_0.copy(),\n",
    "                onevsall_y_train_1.copy(),\n",
    "                onevsall_y_train_2.copy(),\n",
    "                onevsall_y_train_3.copy(),\n",
    "                onevsall_y_train_4.copy(),\n",
    "                onevsall_y_train_5.copy(),\n",
    "                onevsall_y_train_6.copy(),\n",
    "                onevsall_y_train_7.copy(),\n",
    "                onevsall_y_train_8.copy(),\n",
    "                onevsall_y_train_9.copy()\n",
    "            ]\n",
    "\n",
    "x_data = complete_x_train.copy()\n",
    "\n",
    "def getTopFeatureMethod1(x,dataset,arr):\n",
    "    return_arr = []\n",
    "    for i in arr:\n",
    "        bestfeatures = SelectKBest(score_func=chi2, k=x//len(arr))\n",
    "        fit = bestfeatures.fit(dataset,i)\n",
    "        dfscores = pd.DataFrame(fit.scores_)\n",
    "        dfcolumns = pd.DataFrame(dataset.columns)\n",
    "        featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "        featureScores.columns = ['Specs','Score']\n",
    "        return_arr = np.unique(np.concatenate((return_arr,featureScores.nlargest(x//len(arr),'Score')['Specs']),0))\n",
    "    return return_arr\n",
    "\n",
    "def Remove_Outlier_Indices(df):\n",
    "    Q1 = df.quantile(0.2)\n",
    "    Q3 = df.quantile(0.8)\n",
    "    IQR = Q3 - Q1\n",
    "    trueList = ~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR)))\n",
    "    return trueList\n",
    "\n",
    "def getTopFeatureMethod2(x,dataset,arr):\n",
    "    features_array = [[]]*10\n",
    "    return_arr = [[]]*3\n",
    "    for i in range (0,len(arr)):\n",
    "        bestfeatures = SelectKBest(score_func=chi2, k=x//len(arr))\n",
    "        fit = bestfeatures.fit(dataset,arr[i])\n",
    "        dfscores = pd.DataFrame(fit.scores_)\n",
    "        dfcolumns = pd.DataFrame(dataset.columns)\n",
    "        featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "        featureScores.columns = ['Specs','Score']\n",
    "        features_array[i]=featureScores.nlargest(x//len(arr),'Score')['Specs']\n",
    "    for i in range (0,10):\n",
    "        return_arr[0] = np.unique(np.concatenate((return_arr[0], features_array[i][0:x//len(arr)]),0))\n",
    "        return_arr[1] = np.unique(np.concatenate((return_arr[1], features_array[i][0:x//(len(arr)*2)]),0))\n",
    "        return_arr[2] = np.unique(np.concatenate((return_arr[2], features_array[i][0:x//(len(arr)*4)]),0))\n",
    "    return return_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = getTopFeatureMethod1(400,x_data,class_arr_data)\n",
    "temp2 = getTopFeatureMethod1(200,x_data,class_arr_data)\n",
    "temp3 = getTopFeatureMethod1(125,x_data,class_arr_data)\n",
    "\n",
    "temp = getTopFeatureMethod2(700,x_data,class_arr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_outlier1 = Remove_Outlier_Indices(balanced_dataset_x)\n",
    "non_outlier2 = Remove_Outlier_Indices(complete_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dataset_x=balanced_dataset_x[non_outlier1]\n",
    "balanced_dataset_x=balanced_dataset_x.fillna(0)\n",
    "\n",
    "complete_x_test=complete_x_test[non_outlier2]\n",
    "complete_x_test=complete_x_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb=MultinomialNB()\n",
    "arr=temp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6650485436893204\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.34      0.46       131\n",
      "           1       0.61      0.77      0.68       568\n",
      "           2       0.72      0.75      0.74       725\n",
      "           3       0.63      0.63      0.63       446\n",
      "           4       0.66      0.80      0.72       541\n",
      "           5       0.93      0.39      0.55       143\n",
      "           6       0.69      0.38      0.49       164\n",
      "           7       0.55      0.37      0.44        89\n",
      "           8       0.67      0.76      0.71       133\n",
      "           9       0.70      0.42      0.53       150\n",
      "\n",
      "    accuracy                           0.67      3090\n",
      "   macro avg       0.69      0.56      0.59      3090\n",
      "weighted avg       0.68      0.67      0.65      3090\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb.fit(balanced_dataset_x[arr],balanced_dataset_y)\n",
    "\n",
    "y_pred_nb=nb.predict(complete_x_test[arr])\n",
    "\n",
    "print(accuracy_score(y_pred_nb,complete_y_test))\n",
    "print(classification_report(y_pred_nb,complete_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Using Method  1\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 \tMethod 1 \t Gaussian Naive Bayes     \tAccuracy : 0.7378640776699029     \tPrecision : 0.7702593929524392     \tRecall Score : 0.7378640776699029     \tF1 Score : 0.7412212796521143\n",
      "Dataset 1 \tMethod 1 \t Multinomial Naive Bayes     \tAccuracy : 0.6967637540453074     \tPrecision : 0.7319449026969754     \tRecall Score : 0.6967637540453074     \tF1 Score : 0.7047481387379192\n",
      "Dataset 1 \tMethod 1 \t Complement Naive Bayes     \tAccuracy : 0.596116504854369     \tPrecision : 0.7234693698510563     \tRecall Score : 0.596116504854369     \tF1 Score : 0.6353691717840814\n",
      "Dataset 1 \tMethod 2 \t Gaussian Naive Bayes     \tAccuracy : 0.7355987055016181     \tPrecision : 0.7626536446731632     \tRecall Score : 0.7355987055016181     \tF1 Score : 0.7399725291700247\n",
      "Dataset 1 \tMethod 2 \t Multinomial Naive Bayes     \tAccuracy : 0.7025889967637541     \tPrecision : 0.7320815665127461     \tRecall Score : 0.7025889967637541     \tF1 Score : 0.7088916896929455\n",
      "Dataset 1 \tMethod 2 \t Complement Naive Bayes     \tAccuracy : 0.6022653721682848     \tPrecision : 0.7403858695172004     \tRecall Score : 0.6022653721682848     \tF1 Score : 0.6451011403008159\n",
      "Dataset 1 \tMethod 3 \t Gaussian Naive Bayes     \tAccuracy : 0.6880258899676376     \tPrecision : 0.7242885986898332     \tRecall Score : 0.6880258899676376     \tF1 Score : 0.6953186651444442\n",
      "Dataset 1 \tMethod 3 \t Multinomial Naive Bayes     \tAccuracy : 0.6650485436893204     \tPrecision : 0.7059041397617198     \tRecall Score : 0.6650485436893204     \tF1 Score : 0.6752738093173797\n",
      "Dataset 1 \tMethod 3 \t Complement Naive Bayes     \tAccuracy : 0.5514563106796116     \tPrecision : 0.7252286850669106     \tRecall Score : 0.5514563106796116     \tF1 Score : 0.5991245094055287\n",
      "****************************************************************************************************\n",
      "Using Method  2\n",
      "****************************************************************************************************\n",
      "Dataset 2 \tMethod 1 \t Gaussian Naive Bayes     \tAccuracy : 0.7271844660194174     \tPrecision : 0.7729476269196234     \tRecall Score : 0.7271844660194174     \tF1 Score : 0.7319535721665127\n",
      "Dataset 2 \tMethod 1 \t Multinomial Naive Bayes     \tAccuracy : 0.6330097087378641     \tPrecision : 0.6795556064236964     \tRecall Score : 0.6330097087378641     \tF1 Score : 0.644665947149712\n",
      "Dataset 2 \tMethod 1 \t Complement Naive Bayes     \tAccuracy : 0.4802588996763754     \tPrecision : 0.6494672677799845     \tRecall Score : 0.4802588996763754     \tF1 Score : 0.5235631822187521\n",
      "Dataset 2 \tMethod 2 \t Gaussian Naive Bayes     \tAccuracy : 0.7381877022653721     \tPrecision : 0.7708615906093093     \tRecall Score : 0.7381877022653721     \tF1 Score : 0.7419072508624228\n",
      "Dataset 2 \tMethod 2 \t Multinomial Naive Bayes     \tAccuracy : 0.6983818770226538     \tPrecision : 0.7322690863261546     \tRecall Score : 0.6983818770226538     \tF1 Score : 0.7061928218952276\n",
      "Dataset 2 \tMethod 2 \t Complement Naive Bayes     \tAccuracy : 0.601294498381877     \tPrecision : 0.7303528596087302     \tRecall Score : 0.601294498381877     \tF1 Score : 0.6413815445529445\n",
      "Dataset 2 \tMethod 3 \t Gaussian Naive Bayes     \tAccuracy : 0.7210355987055016     \tPrecision : 0.7467998436887078     \tRecall Score : 0.7210355987055016     \tF1 Score : 0.7250452901666283\n",
      "Dataset 2 \tMethod 3 \t Multinomial Naive Bayes     \tAccuracy : 0.6932038834951456     \tPrecision : 0.7331698962101781     \tRecall Score : 0.6932038834951456     \tF1 Score : 0.7019199189028661\n",
      "Dataset 2 \tMethod 3 \t Complement Naive Bayes     \tAccuracy : 0.6275080906148868     \tPrecision : 0.7373650979189249     \tRecall Score : 0.6275080906148868     \tF1 Score : 0.6585329698054377\n"
     ]
    }
   ],
   "source": [
    "datasets = [\n",
    "    [(balanced_dataset_x[temp1], complete_x_test[temp1]), (balanced_dataset_x[temp2], complete_x_test[temp2]), (balanced_dataset_x[temp3], complete_x_test[temp3])],\n",
    "    [(balanced_dataset_x[temp[0]], complete_x_test[temp[0]]), (balanced_dataset_x[temp[1]], complete_x_test[temp[1]]), (balanced_dataset_x[temp[2]], complete_x_test[temp[2]])]\n",
    "]\n",
    "\n",
    "bayes = [\"gaussian\", \"multinomial\", \"complement\"]\n",
    "\n",
    "for i in range (0,len(datasets)):\n",
    "    print(\"*\"*100)\n",
    "    print(\"Using Method \",i+1)\n",
    "    print(\"*\"*100)\n",
    "    for j in range (0,len(datasets[i])):\n",
    "        for k in range (0,len(bayes)):\n",
    "            temp = run_naivebayes(bayes[k], datasets[i][j][0], balanced_dataset_y, datasets[i][j][1], complete_y_test)\n",
    "            print(\"Dataset\",i+1,\"\\tMethod\",j+1,\"\\t\",bayes[k].capitalize(),\"Naive Bayes\",\"    \\tAccuracy :\",temp[0],\"    \\tPrecision :\",temp[1],\"    \\tRecall Score :\",temp[2],\"    \\tF1 Score :\",temp[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
